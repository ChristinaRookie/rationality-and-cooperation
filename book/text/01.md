---
title: "1. Hello World"
style: chapter page-1
---

Written by Christina Tromp

University of Cape Town student number: TRMCHR001

Supervised by Dr George Hull

Programme: Honours in Philosophy, Politics and Economics

Home Department: Philosophy

[Table of Contents 2](#_Toc442015368)

[Introduction 3](#introduction)

[1. Rational Choice as Utility Maximization 4](#rational-choice-as-utility-maximization)

[2. A Paradox of Rational Choice as Utility Maximization 7](#a-paradox-of-rational-choice-as-utility-maximization)

[3. Problems as the Absence of Markets 11](#problems-as-the-absence-of-markets)

[4. Reasons, Motivation and Value 18](#reasons-motivation-and-value)

[5. Rational Action as Based on Good Reasons 25](#rational-action-as-based-on-good-reasons)

[6. The Context for Appropriate Cooperation 29](#the-context-for-appropriate-cooperation)

[7. The Outcomes of a Reasonable Theory of Rationality 36](#the-outcomes-of-a-reasonable-theory-of-rationality)

[Conclusion 39](#conclusion)

[Bibliography 42](#bibliography)

[Plagiarism Declaration 45](#plagiarism-declaration)

When Is Cooperation Rational?

# Introduction

Systemic problems are the result of actions by many people. They are either the excess of some action (like emitting CO~2~ or fishing in the ocean) or the lack of some action (like contributing to the common stock through paying tax); accordingly they require collective action to be addressed. The nature of these problems is also such that ultimately everyone would profit from cooperation, and everyone would suffer as the result of a failure to cooperate, while the benefit and cost to each individual will differ according to their degree of long-term independence with regards to the resource in question. It seems like the reasonable thing to do, if the degree of interdependence is relatively high, would be to cooperate and collectively address problems that affect the collective of individuals, and thereby make everyone better off; but this is exactly the opposite of what economic theorists have predicted people will do.

When we adopt a Theory of Rational Choice that assumes individuals make their decisions in isolation, define their preferences in isolation, and seek always to maximize their self-interest (which is usually restricted to financial outcomes), we are bound to face a number of problems which have no technical solution, where “technical solution” is defined as a solution brought about by a change in techniques and not requiring a change in human values or ideas of morality.[^1] In fact, for collective problems to be addressed, the neo-classical economist can *only* look to technical solutions, or if not available, property rights and sanctions that restrict freedom, in order to prevent mutual ruin in the commons by eliminating the commons altogether. They can never rely on a rational actor’s normative reasons for action which enable appropriate assessment and response to a situation, since morality and social norms have space in the Rational Choice theory only as preferences, and preferences are given, exogenous to the situation individuals find themselves in.

Herein I will challenge the basic assumptions of Rational Choice theory, presenting a picture of human beings who are socially responsive to more than selfish considerations of utility maximization, who value many different things in different ways which cannot be reduced to considerations of utility, and assess their reasons for action and respond appropriately, when they are acting rationally. This will open up a space for investigating the conditions under which rational individuals will act as selfish utility maximizers, and the conditions under which they will actually do their fair share. With new possibilities for rational actors to cooperate some theoretical and practical problems will seem less of a lost cause, but the task of changing social relations to adequately meet the standards of a cooperative endeavour will pose problems for basing relations on market norms and coercive governance.

# 1. Rational Choice as Utility Maximization

Rationality in the Rational Choice model is seen as an instrument to maximize utility, which is conceived as the satisfaction of preferences. Indifference curves map the ordinal measures of the ranking and relative weight of preferences for different bundles of goods; all preferences are ranked by reducing concerns to utility so that this single value can be maximized. The rational actor is supposed to be using this method, implicitly or explicitly, to weigh up the bundles of choice and elucidate the action that will best serve their interests, their utility. This provides the means for choosing between actions, and conceives of rational choice as the action that can be expected to satisfy the individual’s preferences best. In the adoption of this framework, we understand an action as the outcome of competing preferences. Where it is difficult to express which option an actor values most, we can force them to make a choice and use it to depict the evaluation of options.[^2]

According to Arrow, the conditions of rationality, which a supposed rational actor needs to embody before they can even begin to deliberate about maximization, are those of “common sense”.[^3] These are completeness and transitivity. Completeness requires that an actor can rank each and all goods relative to one another, and makes no allowances for being unable to choose between, or lacking an adequate measure to compare two options. For example, I must know whether I prefer working to playing, the measure I must use is simply utility (there is no thicker description such as “I prefer working when fulfilment or esteem are my concerns but prefer playing when stress-release is my concern”), the preference is seen to be given, its satisfaction reducible to utility, and its occurrence unrelated from the situation at hand.

Transitivity requires that if you prefer bundle X to Y, and Y to Z, then you should prefer X to Z. Say, for instance, that you preferred X to Y and Y to Z but preferred Z to X, then you could keep substituting for more preferred bundles and wouldn’t be able to make a reasonable choice, this is the standard argument for transitivity at least (which also does away with thick, contextual descriptions, and assumes that evaluations are reducible to one scale of value, utility).[^4] In the first place, this model assumes that it makes sense to represent all deliberation and choice as a matter of utility maximization (seen as preference satisfaction), and importantly, that all bundles of goods are substitutable for one another at some hypothetical exchange rate for the actor, that all ways in which things are valued can be reduced to a common measure.

Rational action, in this model, is seen as motivated by preferences, relative desires for goods. So for example if empirical investigation led us to believe that someone performed an act of altruism, we would explain this by figuring in a preference for altruism, or a preference for the safety of others that amounted to a personal benefit, an increase in utility, when satisfied. In economic theory, no one ever does “something for nothing”; a rational person would only choose to do an action because the benefits it accrued to them outweighed the costs. However, if we don’t take this as given, it seems fallacious to post hoc theorize and fill in the motivation by assuming a desire for any such thing to make sense of the action. This post hoc inference of a preference for altruism does nothing to provide an independent reason for the claim that action is only motivated by personal opportunities for satisfaction, which the Rational Choice theorists take as a plainly obvious part of rationality (Wiggins).[^5] The theory amounts to a post hoc rationalization of the agent’s choices, rather than a theory that is actually seen to guide or predict choices. In fact, if an agent were simply basing their decisions on the rationale of utility maximization (especially if conceived of as constrained to tangible costs and benefits), *their* “rational” behaviour would seem in need of explanation, one such explanation would be that it was an especially constrained case where only matters of benefits and costs were valuable and meaningful to them (for example, a cut-throat business manager trying to increase his bottom line).

Rational Choice theory assumes that everything comes down to a personal cost-benefit analysis, and no belief about what you “should” do or “must” do can motivate you directly, the only way to account for a normative belief is to fit it into a preference ordering where it must compete with other desires. Desires provide motivation, and no explanation is given to how desires themselves are motivated. In the reductionist framework of value, motivation and desire are akin to urges and likings, given and not capable of being motivated endogenously to rational deliberation. Let us put aside impending worries about transitivity, commensurability of concerns or values, motivation, and conceiving of rationality as a priori and based on purely instrumental deliberation for preference satisfaction. Let us confront a paradox of rationality, assuming for the while the Rational Choice theorist’s conception of it.

# 2. A Paradox of Rational Choice as Utility Maximization

Two individuals each have the option to cooperate or defect (C or D). The payoff structure for the game can be seen in figure 1, where V &gt; X &gt; Y &gt; Z; and 2X &gt; V + Z. When the other player cooperates, the payoff for defection is the best, when the other player defects, the payoff for defection is best, so if one is maximizing one’s own payoff (the assumed point of the game) no matter what the other does, you should always defect. The result is that with both player’s thinking this way, they both defect, and they each a much lower payoff that if they had both cooperated (Y &lt; X).

*Figure 1: A Prisoner’s Dilemma Game*

| Player 1   | Player 2 |
|------------|----------|------|------|
|            |          | C    | D    |
|            | C        | X, X | Z, V |
|            | D        | V, Z | Y, Y |

An example of this paradox pertains to a class of goods often called “common pool resources”, its formal scheme is an iterated n-person generalisation of a prisoner’s dilemma game. While first mentioned by Lloyd, it was only spelled out in full by Hardin in 1968. Hardin called it “The Tragedy of the Commons”, his thought experiment aimed to show that “freedom in a commons brings ruin to all”. Hardin starts by assuring us that “as a rational being each herdsman will seek to maximize his gain”, and asks himself, “What is the utility to *me* of adding one more animal to my herd?” (Hardin’s emphasis)[^6]. The herdsman concludes that it will give him more utility to add another animal than to refrain, and another, and another… Hardin says, “Each man is locked into a system which compels him to increase his herd without limit, in a world that is limited”.[^7] This leads to the degradation of the commons, all the individual herdsmen thinking rationally has the net outcome that the commons is destroyed. This is a sure paradox if there ever was one, the rational action for every individual leads to “mutual ruin”. Rational action, whose supposed point is utility maximization (which surely includes livelihood), serves to undermine the livelihood of the individual when he finds himself acting in a situation of scarcity with other rational people.

But how accurate is this depiction of a context of common property? And moreover, how accurate is this depiction of rational actors? Firstly, Hardin admitted more than 25 years later that the title of his paper was misleading, and that it should have been called “The Tragedy of the *Unmanaged* Commons” (my emphasis).[^8] This is a more accurate title because it insinuates that management can help avoid tragedy. But more importantly, the tragedy is not a tragedy of common ownership (which would usually have some social institutions in place to manage exploitation, coordinate actions and avoid tragedy if there were known conditions of scarcity), but rather, a tragedy of a “free for all”, where no rules apply and individuals have no regard for communal interests, which include the survival of the community for future generations.

The picture of rational actors as isolated individuals maximizing short-term self-interest makes sense in certain conditions. In the absence of social arrangements to ensure others won’t exploit the resource while the individual or community refrains from exploiting it, individuals might exploit to secure their livelihood. In the absence of social support to ensure the individual won’t suffer while others prosper it is rational to increase your herd, one has no good reason to offer oneself up for self-sacrifice, if you can’t be assured that the resource will be here next year, or that you will be here next year, you might as well maximize your production now to save and secure your livelihood for later.

Game theory, based on the rational choice model, holds that commitments never work as norms for action, only as beliefs about what others will do, which helps you to coordinate to find an equilibrium (a stable strategy where no one could be made better off without making someone worse off). In general, commitments mean quite little in the Prisoner’s Dilemma game if the players are relatively short-sighted and self-interested; if the other player assured me they would cooperate or defect, I would still have an interest in defecting always. However, for example in an iterated n-person generalisation of a Prisoner’s Dilemma game, if you knew that when you defected in this round of a game, the community would defect against you in the next round of the game (a strategy called Tit-for-Tat), then you would be better off cooperating if you expect to be around for many more rounds (and do not discount future payoffs too highly). If you started cooperating to maximize your utility, and thereby playing according to a strategy of reciprocity (Tit-for-Tat), the population would converge to equilibrium where everyone is playing according to reciprocity, and no person can get a better payoff by changing only their own strategy. But this would not be a case of you conforming to a norm of cooperation because it is the right thing to do, it would be a case where the utility from cooperation outweighs the utility from defection when the others are playing Tit-for-Tat. Your belief about what the going “norm” is guides your action to maximize your utility, thereby converging to an equilibrium with others. But there are many equilibria in a Prisoner’s Dilemma, one such equilibrium is where all players are defecting all the time, so we cannot count on norms which essentially lack normativity to ensure cooperation unless a large enough proportion of the population already endorses those norms.[^9] As Hardin says, there appear to be no sure technical solutions which would involve nothing in the way of morality or values.[^10]

Hardin discounts any possible solution in the form of human values or morality, by stating that even if it was possible to convince people to do the right thing, guilt is a pathology: when we ask people to take “responsibility” we are essentially appealing to their conscience, and to try and “browbeat” a free man to do something against his interests is to try get something for nothing.[^11] Hardin says there is only one way to make people take real responsibility for the circumstance, create social arrangements. He doesn’t mean anything like the intuitive understandings of “social arrangements”, with implicit social contracts, platforms for discussion to establish mutual understandings of problems and norms for behaviour, or “taking responsibility”, involving self-determination. Rather he means, and says explicitly, that government imposed coercion or privatizing the property is the only way to “free” individuals from mutual ruin.[^12] But monitoring compliance is difficult, and if people are treated as self-interested, natural compliance levels will be low, so presumably an extensive and absolute authority will need to monitor everything and impose strong sanctions on undesired behaviour. Nothing is said of how exactly those institutions will be monitored to comply with their duties in providing the public good of monitoring, perhaps it is assumed that individuals in institutions are more trustworthy and dedicated than citizens, or assumed that a regress of monitoring the monitors on all levels can work (a common goods dilemma with no technical solution that Hardin neglects).

But human beings are capable of drawing on reasons for action which are essentially normative, not self-interested, and can be motivating forces for action, such as “I ought to do my part in a cooperative endeavour”, or “I should not exploit other people’s goodwill”. These norms can bypass, shape or silence one’s desires when the context is seen as appropriate. Norms or appeals need not be sickness inducing appeals to conscience, but in some cases they will rightly make individuals evaluate themselves against their ideals, and in no way does this appeal to integrity and conscience embody any “pathology” or inherent weakness of human beings, living up to our own norms and ideals is rational and necessary to living a good life as social beings with the need for coherent narratives. Shame, a self-evaluative emotion (which Hardin reduces to guilt), is a powerful tool for self-reflection and improvement of action. I will leave that thought with you until § 4.

# 3. Problems as the Absence of Markets

When a tragedy of the free-for-all arises, it is, according to neo-classical economic theory, for one reason only: no market exists for the land, being free of charge massively undervalues the land, whose price should rather be set by equalizing the supply of land with demand. This is an example of so-called market failure: the market has failed to match supply with demand because an externality exists, i.e. there is a cost imposed on a third party rather than internalised by the parties who the cost originates with. Assuming the parties are purely self-interested, the only way to internalise the cost is to be charged for it. In this way market failure is an indication of the incompleteness of markets, not an indication of any real defect with them or the values of the actors within them. One way to extend the market would be to establish property rights and sell the rights to the highest bidder (whoever values it most in monetary terms), and then whoever acquires the property can determine a value for the good by setting a price (a willingness to accept), and people who are willing and able to pay (who value the good at least as much as the seller’s willingness to accept) will pay and use the resource. In this way, so they say, those who value the good the most (expressed as willingness and ability to pay) receive access to it. Both parties are better off after the exchange, which is inferred by the fact that they engaged in a voluntary exchange to acquire a good that they preferred to their original endowment. But nothing is said of those who are excluded, they presumably don’t value the good enough to pursue it, when we take value as indicated by willingness (and ability) to pay.

Another way to put an “appropriate value” on a good to eliminate the free-for-all tragedy is for the government to determine an appropriate value for the good (which they do by cost-benefit analysis, assessing the value of production or services that the good supports and how much people will pay for them) and effectively charge a price for exploitation in the form of taxes or fines. Given the increased cost of exploitation, users will exploit less; this is the price effect on demand that will match it with supply. Matching demand with supply, in either case, is meant to introduce a market to ensure efficiency. The method for enticing self-interested and isolated individuals to conform to better practices can simply be called “incentivizing” (a relatively recent word in economics, first used in 1968)[^13] and is equivalent to the term “coercion” that Hardin and his predecessors used in this context. Behind both of these solutions, and the theory of market failure, is the First Fundamental Theorem of Welfare Economics.

The First Fundamental Theorem of Welfare Economics says that when a perfectly competitive market economy is in equilibrium it is allocatively efficient, i.e. Pareto Optimal. Pareto Optimality refers to a state where no one person can be made better off without making someone else worse off, so equilibrium should be indicated by no more voluntary exchanges taking place, as all opportunities for mutual gain have been exhausted.[^14] In this way goods have found their way into the hands of those who are said to value them most, and it is efficient. But a number of conditions must be in place if the theorem is to hold; there must be perfect rationality of agents and perfect information, property rights must be well-defined and costlessly enforced, transaction costs must be zero such that trade can happen easily anywhere, there must be no externalities on third parties, and importantly, all commodities must be infinitely divisible and substitutable for each other.[^15] But efficiency does not actually guarantee properly valuing things or people, or ensuring justice or conservation. Slavery could be Pareto Optimal, you couldn’t make the slaves better off without making the slave-owners worse off, and no voluntary exchange would take place if the slaves were not “willing” to pay the price for their freedom. Similarly, if people are not willing to pay to clean up an oil spill, the oil spill could still be considered “efficient”, because the value of cleaning it up is not discernible in their consumer choice; what counts as an externality are only those costs that are discernible from a third party’s elicited preferences in choices of consumption.

Arrow and Debreu formalised this general equilibrium with a complete market, a market for every good, including not just present goods and consumers but future ones too.[^16] Economists insist their theories are value-neutral (even though the whole purpose of the theorem at hand is to maximize “social welfare”, seen as maximizing individuals given preferences through ensuring efficiency); they leave all questions of ends up to consumers themselves, ensuring efficiency through allocations which are represented in utility rather than any specific goods, since all goods are substitutable. This provides the means for the aggregation and maximization of preference satisfaction. But clearly there are no needs such as water or air in neo-classical economic theory; there is nothing specific that we must leave to individuals of the future except bundles of goods or money to be exchanged for goods they might prefer. Efficiency doesn’t imply conservation or meeting needs (which are distinct from strong preferences signalled by willingness to pay), thus there is a case for regulation of the distribution and occurrence of certain goods, because achieving maximum “social welfare” by allowing the satisfaction of preferences through voluntary exchange does not ensure justice or even the survival of consumers. There are some things that we value that cannot be expressed in our preferences for goods and willingness to pay for them. Even if the market is complete and frictionless etc. it can surely still said to have “failed” if it fails to meet needs and achieve a true or even minimally adequate social welfare.[^17]

In practice the conditions look like utopian assumptions anyway. Complete and competitive markets in a frictionless economy are unrealistic assumptions, and the rarity of identifying a Pareto Optimal equilibrium (or a Superior allocation which moves towards it) leads policy prescribers to use a different principle for allocative efficiency, the Kaldor-Hicks principle. This principle advocates a move to a point where someone is better off, and another party may be worse off, but the gains to the first party are so great that they could hypothetically compensate the party who is made worse off and still have extra gain.[^18] Compensation for the loss is not enforced, and in principle the theorem is perfectly compatible with extreme misery being compounded while extreme wealth grows. This is the practical outcome of their quest for welfare through efficiency. Questions of justice (distribution) and conservation (occurrence) aside, the condition which is most worrying for my purposes here relates to the divisibility and substitutability of any good with any other good (the character of how we value goods), which requires that everything of value is commodified such that a market exists for it, and that for any agent who prefers a bundle of 3x and 1y to one with 3y and 1x, there exists some extra amount of y that she could be given that would reverse her preference for the bundles. It requires that people value things as exchangeable with any other thing, and that everything of value be commodified. I will return to this criticism in the next section (§ 4), after engaging with some more examples of addressing market failure, which will illuminate the points I aim to make further on.

Markets can also be established to ensure the provision of a pubic good, which while sharing the formal structure of a social dilemma with common pool (free-for-all) resources, relates to *provision* of non-excludable resources rather than *restraint*. Everyone is better off if everyone contributes to the public good, but each individual is assumed to have the short-term self-interest that makes “Don’t Contribute” a dominant strategy, with the result that the good is underprovided and everyone is worse off. One could ensure adequate contribution by enforcing it, monitoring contribution and fining those who don’t contribute. Another standard economic method is to actually pay people to contribute, for example paying people to give blood or to have a toxic waste site in their community. All these methods work by changing the payoffs of actors, making contribution or restraint the more beneficial course of action. But often the implementations of such schemes lead to outcomes that confound standard theory. When a payment to people or sanction on them to “do the right thing” leads to less of the right action, it completely violates the price effect, adding more financial benefit to choosing the socially desirable option leads to less supply of that action.

Finding a place to store nuclear waste is no easy task. In Switzerland parliament designated the small village Wolfenschiessen as a potential candidate for storing the country’s waste. Before a referendum was held, they surveyed the villagers and asked if they would vote to accept the siting in the village if it was found to be the safest potential site. 51% of the villagers said yes; despite the undesirable risks and costs that it would impose on them, their civic duty appeared to weigh in on their decision: their country depended on Nuclear energy whose waste needed to be stored somewhere.[^19] Hoping to increase acceptance, the villagers were questioned again and were offered an annual payment for the siting of the waste depository in their village. The financial incentive had the effect that acceptance decreased from 51% to 25%. When the incentive was increased, even to $8,700 per annum per person, acceptance did not go up. 83% of the rejecters of the offer explained their stance by saying they could not be bribed.[^20] Frey and Oberholzer-Gee who compiled the study stated that “incentives tend to crowd out civic duty”, transforming a matter of civic duty, where what matters is that the village is providing a socially desirable (albeit locally undesirable) good, to a matter of personal fiscal benefit and personal risk.[^21] The monetary incentive made people feel like they were being bribed, exploited, and unsure of whether they were part of a civic, cooperative endeavour. Citizens tend to resent their public duties or acts in the name of public spirit being treated as if they are matters of cost-benefit analysis (and compensable with money). The result of numerous studies is that Public Goods (such as libraries and better schools), like returning gifts in kind, are preferred to monetary compensation, because they acknowledge public spirit and sacrifice, rather than degrading the value of what the citizens have done, as if they simply participated in a business deal.[^22]

Another example of the apparent crowding out of moral or civic motivations is a case of experiments of day-care centres in Israel. There were some unwanted late pickups of children and to ameliorate this a fine was enforced. The result was that late-pickups nearly doubled, the explanations given by analysts of the situation state that the parents’ treatment of the decision of whether to be late or on time became a fiscal one (and they were willing to pay for being late) rather than a moral one with concern for the care-givers.[^23] The same scholars conducted an experiment incentivizing groups of high-school students doing door-to-door collections of donations for good causes. Three groups were each given a motivational speech, but then offered differing financial incentives. The first group, offered no incentive, collected 50% more than a second group given a 1% commission, and 9% more than a third group given a 10% commission.[^24] The authors’ conclusion is that incentives only work better than no-pay for good deeds when they are sufficiently high.[^25] That statement is close to tautological, stating that incentives work when they adequately incentivize; but moreover, the case shows that financial incentives are not additive with moral or intrinsic incentives; they were all given a motivational speech.

A last example forms a comparison between blood donation systems in the UK and the US, where in the former blood is provided by donations, while in the US people are paid for their donations or are allowed to refuse the money if they like. In his book *The Gift Relationship*, Richard Titmuss presented this case and argued that on “efficiency” terms alone, the donation system worked better: the US system had more chronic shortages and wasted blood, higher costs, and a higher risk of contaminated blood. He also added that it was exploitative of the poor, stating that it was a sort of redistribution of blood from the poor to the rich.[^26] The main conclusion of his book, however, was that commodifying blood undermines a Gift-Relation, and that commodification of the US system had led to a decrease in donations. He worried about the decline of altruistic motives, the “theme of the gift”, when giving blood became a predominantly market transaction rather than an altruistic act that was an active feature of social life. He anticipated that such a decline in altruism would spread to other spheres of social life.[^27]

In all four cases a provision or fulfilment of a perceived duty was at stake. Let us call doing the socially desirable thing X and doing the socially undesirable thing Z. In each case, some amount of people preferred X to Z, and some preferred Z to X. What we would expect is that if we made X more beneficial for the individuals, more of them would “prefer” it, i.e. choose to do it. The benefits to those who already chose X over Z were supposed to simply be greater than before, so their preference orderings would stay the same, and the number of people who chose X (chose to accept the site, arrived on time, collected lots of donations, and donated blood) would increase. Undoubtedly those who were interested in the extra benefit, like the extremely poor people donating their blood for income, would have increased their provisions (chose X) because it was more financially beneficial to do so. But let us analyse those who *already* chose X in the first place, their initial preference was for X &gt; Z, an incentive was added such that X + benefit &gt; X, and somehow their choice reflected that Z &gt; X + benefit; their provisions decreased relative to the stage where no incentive was present. These are intransitive preferences (X&gt;Z; X+benefit&gt;X; Z&gt;X+benefit), violating the Rational Choice axioms. Joseph Raz takes this sort of intransitivity as a sign of incommensurability, a sign of things being valued in different ways, which will be picked apart in the next section (§ 4).[^28] Suffice it to say here that if there were benefits from doing the socially desirable action to begin with, they were not additive with financial incentives for the individuals making a choice. Their moral and intrinsic motivations were crowded out by the introduction of incentives that provided a cue for the context to be governed by market reasoning and norms. The value of the action for the actor was changed from a personally, publicly, morally, or intrinsically valuable action, and evaluated in those ways, to one that was evaluated by a market analysis (and was not sufficiently financially valuable to induce the socially desirable action).

# 4. Reasons, Motivation and Value

The empirical cases wherein people responded in a manner contradicting the expectations of Rational Choice theory can only be understood if one accepts that they were not trying to maximize value in the monistic sense, as equivalent to financial benefit. If we assume that they received some benefit from their acts of giving, and that value is summative on a single scale, then adding an economic incentive to the existing benefits should have been additive. Instead, the added economic benefit yielded less of the activity; their motivations and reasons for action were undermined, not reinforced, by economic benefits. Some people will be adequately incentivized to do something because of a financial reward or a sanction that amounts to a cost, but then the motivating force for doing the action because it is right, or valuable in itself, is unlikely to play any part. Rather, the reason for action will be a desire for personal benefit. The context of provision changes from a relational model of communal giving and equal participation (doing one’s part) to a purely economic relation, wherein the only question becomes “does it pay to do this?” With non-additive values we have reason to doubt a monistic value scale such as utility. We have reason to believe that people value things in different ways, and sometimes in ways that are not commensurable with money.

Before we get to commensurability, the first assumption in the second sentence of this section also deserves questioning. Did they receive some benefit from performing a civic duty or conforming to a moral norm? Perhaps they did, perhaps the actions made them feel good as a by-product, providing some benefit to self-esteem. Many theorists have tried to accommodate a preference for contributing to other’s well-being, or a preference for conforming to a norm in their analysis of rational decision-making. Confronting the results of Titmuss’ *Gift Relationship*, Arrow suggested that an individual preference to contribute to the well-being of others should be included in utility function of some individuals.[^29] Such accommodations play havoc with the constrained individual benefits that are required to maximize social welfare, illustrated by an example given by Elster: two boys find a chocolate cake, the first boy says “I want all of it”, the second boy says “we should share”, an adult comes along and says “Gentlemen, compromise! Three quarters for you, and one quarter for you”.[^30] This division cannot be said to really maximize welfare, even though it was a compromise between their two elicited preferences, and I am inclined to say that the second boy’s self-interest surely included as much cake as possible, and a belief that they should share or compromise moderated his selfish interests and motivated his proposal. Moreover, it is plainly misleading and desperate to conjure up such a preference post hoc to fit the Rational Choice model to cases of actual rational choice; it does nothing in the way of explaining how people are motivated, and why in some contexts their “desire” to help others would be absent or undermined, it simply assumes that such a desire must exist because preferences, desires, and self-interests are inferred from choices.

With the second boy, and with those who wanted to perform civic duties, was an expected by-product of preference satisfaction (where their preference is standardly read off their elicited choices) their *reason* for action? Do people perform civic duties, house toxic waste sites and share cake because it gives them satisfaction? If we say yes, we are bound to abandon all notions of altruism or morality, properly conceived as motivated by other regarding, not selfish, considerations. Rational Choice theory can only understand rational actions in terms of a calculated weighing up and trading off of preferences to determine which action would maximize personal utility, and as such any motivation to do something can be found in a preference constituting the desire for the satisfaction of that will. Desires, represented by preferences, are the motivating force for any rational action. No norm, social or moral, has motivating force unless it is represented by preferences in the utility function.

Taylor calls this strand of thought a Neo-Humean conception of motivation[^31], presumably relating back to Hume’s statement “Reason is, and ought only to be the slave of the passions”.[^32] But Taylor contends that beliefs can have more power than the Rational Choice theorist gives them credit for.[^33] Beliefs, especially those that constitute norms for action, which say what one should or must do in a circumstance, can motivate action directly, and cannot be included as mere preferences. For example, a person at a party may moderate the motivational force of her preference for more cake because she knows that someone else wants it. She may still have an unsatisfied preference for the cake, and crave it, but her desire is weakened in motivational force by a belief that she should let someone else have it. Similarly, if a man desires to cheat on his wife, he might discount this desire by the belief that it would be wrong to do so. His desire might be strong all the same, and he may not feel satisfied at all, but he recognizes that the desire is not a good reason for action.[^34] In these cases it would be misleading to say that if they had chosen cake and cheating respectively, it would prove that their desire for that option would have been stronger or the desire for restraint would have been weaker than in the first case of restraint. It might go to show that the actors in the cases of restraint have beliefs about what is right and about what considerations count in the context that motivated them differently to a cost-benefit analysis of the actions that would most satisfy their desires.

If we insist that as a rational action restraint must be understood as based on a desire for such a course of action, then the desires themselves still seem to be motivated, and are not just given tastes.[^35] They are motivated by beliefs, by the belief that having the last piece of cake would be wrong, or the belief that cheating would be wrong. The desire seems to be motivated by a belief or standing concern, and especially influenced by the situation at hand. If one felt like it was a competitive scenario to get the last piece of cake, or that the other person who wanted the last piece had already had two pieces, such that you didn’t see restraint as the fair choice, the desire to give the other the last piece of cake would not arise because a motivational concern, a reason for restraint, would be lacking. The usual preference for more cake rather than less would dominate the action. Beliefs and concerns can motivate action and be called upon in appropriate situations, but beliefs and concerns themselves can be shaped and informed by reason, reason is not only a slave of given exogenous passions. The social and moral norms, which are essentially normative for action and inform, shape, or silence our desires, can also be changed and influenced by reason, a point I will expand on in the next section (§ 5).

Different norms apply to different contexts; a context of civic life with rights and duties differs greatly from a market transaction. A market transaction treats people as consumers, who are selfish and have no duties to anyone else, not citizens, embedded in a community and capable of doing their part voluntarily (without coercion or bribery). People have no reason to comply if they would rather be treated as citizens, they feel like they are being “bought off” (bribed), and have no assurance that they are part of a civic cooperative endeavour and won’t be exploited. In such a context a motivational concern to do one’s part for the public becomes irrelevant, because there is no such standing concern in purely economic relations. The two negotiating sides seem to be working in different relational models, with different concerns and values, until the market model becomes dominant. The way people value goods and conceive of evaluation in a circumstance can actually be changed by commodifying a good.

Arrow commented on Titmuss’ results, responding to his claim about the change of values by a change in relations. Failing to understand the significance of reasons for action, and how courses of action can be changed in significance to the actor by commodifying them, he stated, “If to a voluntary blood donor system we add the possibility of selling blood, we have only expanded the individual’s range of alternatives. If he derives satisfaction from giving… he can still give, and nothing has been done to impair that right”, “why should it be that the creation of a market for blood would decrease the altruism embodied in giving blood?”[^36] He refused to accept that commodifying a good could change the context to one dominated by market norms, could change the significance of the context and the good for the actor. Then he recommended the inclusion of a preference for helping others to be added to the utility function.[^37] This would only do the requisite explanatory job for Titmuss’ results if he included a clause stating that the preference for helping others was incompatible, and therefore non-additive, with an economic incentive, (i.e. to say that people’s “altruistic” motives were displaced because the benefit of giving was constitutively incompatible with the good being a commodity). The hypothetical clause would go some way to admitting incommensurability: that different motivational concerns of the agent didn’t add up or trade off on a single scale.

The concept of commensurability in this context depicts that for a rational agent with a valuational outlook, there always exists an account of how different concerns trade-off for them.[^38] An agent can say how the two goods or different concerns that they embody are ranked as more, less, or equal in value up against a common measure. (For example, you must be able to measure the values of serving yourself, other people, and the environment against one another, and say which one maximizes your utility, and adjust your action accordingly). This amounts to an agent being able to reduce valuational concerns to a single scale of value (that is generally applicable to all contexts) and measure and weigh all values up against each other by that measure. Practical choice is depicted as reducing concerns to a single measure of utility (and commensurable with money), and maximizing that measure. Incommensurability amounts to the opposite of this, and a mark of it is the kind of intransitivity we encountered in § 3.

Incommensurability of goods or concerns says that there does *not* exist one scale of value on which all values and concerns are measured and which informs practical deliberation in all cases; agents value things in different ways and make their decisions by deciding which concerns matter under the circumstances, often there is no weighing up at all of concerns that would matter elsewhere but seem irrelevant under the circumstances. There is no determinable or projectable rate by which a rational agent trades off all concerns in all contexts. Even if an agent is able to make a decision between two goods, which appear to hold different values for them (such as choosing work and money over family and friends), this does nothing to prove that the distinct concerns can be generally reduced to a single measure with the aim to maximize anything, and does nothing to explain the motivations figuring in to their choice in different circumstances.[^39] Agents learn how to make decisions by learning how to value things, determining what it is they should be concerned about, and reinterpreting these concerns and the conceptions of when they should apply, by orienting and defining themselves towards distinct aims, commitments and values. They often face tough decisions where the distinct and mutually irreducible claims of two concerns cannot both be satisfied, where their distinct commitments and values may call them in different directions. This is the difficulty, but reality, of practical deliberation and choice, among individuals with unique orientations and distinct normative concerns, who are making decisions and refining and redefining their values and assessing the appropriate action those values call for along the way.[^40]

Every relation embodies different norms for action (and distribution), and distinct ways of valuing the parties to the relation and the goods in question that they must distribute between them; it just happens to be the case that market relations and norms value all goods instrumentally, conceive of all parties as consumers or exchange partners instrumental to each other’s utility, and are dominated by selfish and fiscal reasons for action. Instead of appealing to consumer preferences to decide how to provide and distribute goods, we should rather ask what attitude (preferences for the Rational Choice theorist) we want to promote and what relational models are appropriate to such promotions of value that would achieve an adequate, sustainable and fair provision. This goes beyond efficiency to include questions of relations (of which norms and values form a part) that influence provision and distribution, because these further concerns often capture differences in efficiency as well if not better than preference satisfaction (as in the Gift-Relation of blood case), and capture the failure to value goods appropriately that can lead to market failure and social dilemmas, in such a way that there are steps towards solutions that can be made.

Preferences, inferred from choices, and taken in Rational Choice theory to indicate value, can actually be changed by the context (relationships and social institutions); they are not exogenous and influenced by the agent’s given tastes alone, they are not wholly autonomous. There may be different contexts in which preferences and values are distinctly different, and thereby new possibilities for welfare that weren’t even possible before. In this way it is circular to appeal to the satisfaction of preferences to justify the introduction of a market and the claim that maximizing preference satisfaction will maximize welfare.[^41] Different values are actually promoted by different relations, actors respond to the world by determining what the appropriate way to act would be in the given circumstances, and often this has nothing to do with considerations of money or personal benefit.

# 5. Rational Action as Based on Good Reasons 

The Rational Choice model conceives of rationality as a means to given ends, which can all be reduced to the actor’s utility. Goods, people and ideals are all conceived of as instrumental to the agent’s utility. But rationality is about more than maximizing a given end; it requires that the ends themselves be valued appropriately and based on good reasons, and action motivated by those reasonable ends in turn. Good reasons for action are themselves determined by rational reflection, and used when a context is rationally conceived as an appropriate one. Reason has taught people when to use self-restraint, which passions or desires are worthy of satisfaction, and which would undermine other values. Reason has taught human beings that empathy should be expanded to other people, people outside of their tribe or seemingly different to them, to women and even to animals. For example by taking basic claims like “it is wrong for you to do that to me”, and formalising it to yield “it is wrong for x to do that to y”, and substituting “me” and “you” for the pronouns, we get a more universal, rather than compartmentalized self-serving, morality. It allows people to leave their parochial vantage point and assess their ideals and norms for action (how they express their ideals) to achieve greater harmony and consistency between them, and in leaving this vantage point, assessing more than their isolated self-interested or tribal concerns. Rationality provides the basis for questioning how things are valued and how those things should be treated accordingly.

Practical reason is not perfect, but in its practicality it is a matter of learning, improving and expanding its realm. With bad ends an a priori instrumental rationality and the contextual consistency it serves can worsen irrationality in practice. The Rational Choice model unreasonably takes all ends as given and not of importance to reflective deliberation.[^42] It takes rationality as conceived independently to morality, context, or agent-centred ideals, as if we were not capable of expanding and improving our use of rationality beyond the Rational Choice model. Of course, instrumental rationality is undoubtedly useful when the rational concerns of a context *can* be reduced to one measure, it *can* help us maximize that value and achieve our ends. But our ends, our distinct values, and the way our actions fit our values (our means fit our ends), are all in practice constantly reflected upon and rightfully so. In this way fuller practical reason both explains human behaviour and guides it to improve.

Rational actors may value many different things in different ways, and it is their task, and the task of philosophy in particular, to reflect upon, assess and critique the different ways in which things are valued, whether they are appropriate to the goods in question, how those things are treated in turn, and whether those evaluations and practical treatments are consistent. Philosophy should participate in the critique of people’s reasons for action, whether valuing things in certain ways is degrading or fetishizing, and whether our social practices and norms for action adequately express and promote appropriate values. The objectivity and justifiability of values and attitudes towards things must be assessed, and in this way distinguished from matters of taste. Anderson provides three types of critical strategies to aid in the assessment of the justifiability of norms expressive of values, Internal Strategies (which include internal coherence testing, narrow reflective equilibrium, and idealistic self-criticism to test integrity)[^43]; Scientific Strategies (by revealing factual concepts which are at odds with empirical knowledge; showing that an ideal is Utopian; revealing viable alternatives to the norm where it was thought necessary; showing a norm has become historically pointless due to changing circumstances; and genealogical criticism which reveals incoherence or self-deception in the genesis of the norm)[^44]; and Experiential Strategies (where novel encounters or being persuaded by the experience of others introduces new considerations and evaluations).[^45] As the web of communication and the realm of critical reason expand and become more accessible to everyone on the earth, we can expect that if parties accept that their values and norms must be justifiable to others (if they attempt to be reasonable), then new opportunities for claiming objectivity and justifiability will enhance the rationality of practical reason, and guide our actions on better reasons.

In deciding what concerns matter to us, we embody more than instrumental concerns for our own “utility”, we act in accordance with our ideals that are constitutive of our identity, our genuine commitments and concerns, and establish coherence in our lives; when we fail to do so we experience shame, we evaluate ourselves and see that we have failed to live up to who we aspired to be.[^46] We recognize that we were motivated or swayed by reasons that we do not endorse as good reasons in those circumstances. We feel like we cannot justify our own actions to ourselves, let alone justify them to others. Being able to justify one’s actions to others is an important part of seeing oneself as having a good reason, or an objectively right norm for action under the circumstances. For example, in a cooperative endeavour if I exploit the kindness of others on selfish considerations, I will likely be unwilling to express that to them, and most unlikely to endorse those reasons for action as objectively right. If it was a competitive situation, where the going norm was to look out for oneself, then it is likely that I will be very willing to tell others that my reasons for action were calculated selfish considerations, and would be alright with them doing so. We aim to live in a way that we can justify to ourselves, and in turn, justify to others; whether they agree with all of our ideals or not, we need to justify ourselves, and make sense of our lives and the actions which form them.

Problems are more than the absence of markets for rational decision makers, and could be due to inappropriately valuing goods, having uncoordinated norms for action that do not fit or express the appropriate value of a good, or an inability to act in accordance with their appropriate valuations because choices are limited by one’s situation. Since social relations embody norms for valuing people and goods, and norms for appropriate action towards people and the distribution of goods between them, social relations are a key to changing attitudes towards use, provision, and the problem in general. Beliefs about the relations we are part of, how *we* are valued, and how we are expected to behave in those relations influence our concerns and motivations for action. We do more than converge upon one of a number of possible equilibria with others, beliefs help guide action by guiding our decision about which concerns matter under the circumstances, and those concerns motivate action directly. It is more than a matter of beliefs about what other people are doing (social norms), predicting other people’s action and allowing us to maximize our own utility with that information; we find ourselves and our values in our relations with others, and hold ourselves up to those standards that are created and justified communally.

**  
**

# 6. The Context for Appropriate Cooperation

Social Dilemmas (the iterated n-person generalisations of Prisoner’s Dilemmas, which we encountered in §2 with Hardin) are structural, rather than incidental problems.[^47] In this way cooperation is distinguished from an isolated act of helping, it is a sustained effort, comprised of many interdependent individuals who are all affected by the levels of cooperation.[^48] The nature of the “game” is such that people will all be better off if they cooperate, but an emphasis on competition for self-interest satisfaction as opponents leads all of their individual interests to be undermined with the social interest. In order for people to cooperate, they must feel like they have a good reason to do so, I have never denied that, all I have argued is that assuming actors are motivated solely by individual costs and benefits, and incapable of having normative reasons for action, is misleading and detrimental to levels of cooperation when the implications are imposed on the actors. Awareness of the problem, willingness to contribute, and the perception of potential efficacy determine individual cooperative behaviour.[^49] One way in which actors can try overcome the dilemma is to move beyond their parochial vantage point and realise that they would all be better off if they coordinated their actions to cooperate; but it would still pay more for a few individuals to defect while other’s cooperated, and those who were committed to cooperating would in theory face a second (and regressive) public goods dilemma when they had to enforce the norm or monitor compliance. Regard for the common good, norms that promote motivations to act for the common good, and conformance to the norms, are all important for the common good to actually be achieved. Let us go through these challenges with some suggestions from empirical studies on such “dilemmas”.

Understanding the relevance of the promotion of the common good, properly valuing it as well as the others who will benefit from it, and seeing oneself as depended upon in the situation, are all important to increase ones regard for the good in question, and thus to provide a motivational reason for action. In this way the problem is not approached as a dilemma (a conflict between individual and collective interests), it is approached as an opportunity for collective action to achieve everyone’s aims. Even in the absence of such cues and induced motivations, standard prisoners dilemmas have been found to produce much more cooperation than expected by Rational Choice Theory: in a meta-analysis of lab’ games played from 1958-1995, the average rate of cooperation was 47.4%.[^50] This level of cooperation is hardly negligible, and serves to show that the Rational Choice model is at best incomplete as an explanation of behaviour, and at worst, radically wrong in the first place about rational actor’s reasons for cooperation.

Social norms and ideals that express the regard for the common good, and promote it, are essential to entrenching and actualizing a (socially and individually aligned) desired result. Cialdini et al. draw a distinction between injunctive, and descriptive norms. *Injunctive norms* describe what you think others would approve of; *descriptive norms* describe what you think others do in practice.[^51] The strategy Tit-for-Tat does so well in Prisoner’s Dilemma simulations precisely because it is “nice” on the first round, providing clear expectations of its behaviour, a descriptive norm, to other participants; and because it punishes non co-operators and forgives them after that, providing a clear injunctive norm of reciprocity.[^52] In some experiments when the Social Dilemma games were relabelled as “Community Game” rather than “Stock Exchange Game”, cooperation increased, as it did when players were given descriptions that used the words “trust” and “cooperation” rather than “bargaining” and “competition”.[^53] Another separate and significant result of iterated experimental games was that labelling players as “opponents” produced significantly lower levels of mutual cooperation (27.3% and mutual defection: 53.8%) than when they were labelled “partners” (46.6% and mutual defection: 29.7%), the authors of this study conclude that relational models can “awaken” competitive, individualistic and egoistic behaviour, which is detrimental to total payoffs and goal accomplishment when there is mutual dependency on each other’s choices.[^54] The reframing of the situation does nothing to physically change the payoffs of the players, but it subtly tells them how they should value and treat each other, and influences their reasons for action.

Attempting to include social factors (such as social norms) in an expected utility function does nothing to prove that individuals actually gain utility from those social factors; it rather tautologically states that since individuals act off considerations of utility, there must be some added utility to them of those social factors which motivates and explains their action, rather than being motivated directly by one’s conception of the right thing to do. In experiments of social dilemmas without sanctions, with weak sanctions, and with strong sanctions respectively, the strong sanctions groups performed the best, the groups without sanctions did almost as well, and the groups with weak sanctions did significantly worse. When asked to choose how they framed the question, most of the participants in groups with strong and weak sanctions chose “business decision”, and the groups with no sanctions were more likely to choose “ethical decision”. They note that when strong sanctions are in place we can also expect more cooperation, but the basis for it (namely, a cost-benefit analysis result) will be very different from cooperation under a situation with no sanctions, “the sanctioning system influences the frame, but it is the frame that determines the behavior.”[^55]

The lab’ results go some way to showing that, at least, context matters when explaining or predicting rational choice; the net and individual outcomes are heavily influenced by the distinct nature of the context and framing for determining appropriate action, given by cues to social relations and norms of the community. In the end, norms for action that embody social relations determine the level of cooperation. Those that are, in Fiske’s terms[^56], formed on an Equality Matching or Community Sharing relational model rather than a Market model, do better in net and individual outcomes, although the dominant choice under the Rational Choice framing of the situation, if one knows the game will end, is to always defect. Cases in the super-contextual and socially embedded outside world provide further and stronger evidence for the effect of relational models and norms for behaviour on reasons for action and cooperative behaviour.

Klandermans found that a cost-benefit approach was unable to explain cooperation in social movements (conceived as a public good), and that an identity tied to the social interest was essential in determining actions on behalf of the group.[^57] In a study of fishermen’s compliance with regulations in the UK, Hatcher et al. found that a significant proportion comply even though probability of detecting defection and the amount of the penalty are low. They found that psychosocial factors such as feeling of involvement with the management system, a belief that quotas should be complied with even if they were (distributively) unfair, and the perceived attitude of peers to violation significantly determined the probability that an individual would comply, as well as the expected factors of perceived probability of getting caught and the anticipated fine.[^58] Violators were found to have a much higher expectation of violation of their peers; and a perception that “outsiders”, EU fishermen in the UK local waters, were not complying also had a negative influence on compliance.[^59]

Elffers found that although most Western tax administrations don’t have regular audits and the possibility of fraud detection is rare, a large proportion of people pay tax and comply, significantly overcoming or avoiding a public goods dilemma; he found that if people held the belief that others were better off in the system (not doing their fair share), they were less likely to pay tax themselves.[^60] Tyler found that in cases where collective restraint is necessary to manage a resource, willingness to comply with authorities’ regulations was linked to procedural fairness, because procedures convey information about the status of the community, and individual’s standing within the context, shaping individual’s identities and commitments to the community.[^61] Cropanzo and Byrne found that workers commitment to their firms and dedication to the firm’s interest (where the shared goods of high productivity for high wages and profit are at stake) were more significantly determined by perceived *procedural justice* (the rules determining pay and status) as well as perceived *interactional justice* (the relation between the worker and their manager) than simply *distributive* justice (fairness of pay). A lack of procedural and interactional justice was found to decrease trust and commitment to an organisation.[^62]

Many scholars have also found that *commitment* strategies work better than *control* strategies in the workplace.[^63] Communicating a lack of value of or trust in the employee, as simply a producer and seller of labour, as someone who seeks to minimize their effort and production levels (as predicted by the Rational Choice model), rather than someone who is trustworthy and valuable to the organisation, serves to displace their intrinsic and normative motivations, resulting in lower productivity, lower happiness at work, and alienation from each other and the practice.

Conformance to the norms is likely to be greatly influenced by the convergence and expression of collective interests in action. However, if a system of monitoring is needed in order to establish norms and convince individuals that others won’t exploit their efforts, communal monitoring should be used wherever possible. Not only is it often more effective to monitor horizontally and on a smaller-scale than costly and difficult hierarchical and large-scale monitoring, it also promotes trust and cohesion at the “meso” level, and influences the individuals’ views about their community standing and self-standing in the context.[^64] The provision of communal monitoring and sanctioning is itself a public good, but the self-determination, actualization of interests, and opportunity to do the perceived right thing that it provides results in the actors overcoming a regress of public goods dilemmas, which constitutes a solution (albeit involving human values and morality), to social dilemmas.[^65]

If monitoring systems must be enforced (such as when that would help to signal procedural fairness and provide necessary social norms), community support and engagement in design, and thereby identification with the social good, should be allowed and promoted, rather than imposing commands for action from above. This avoids the signalling of mistrust of actors and a low-status of them and their community relation, and avoids the entrenchment of selfish market norms which sanctions have been shown to induce. For this reason Van Vugt advocates scale-reduction of dilemmas to ease the communication of the problem, increase the actor’s relevance in it and the perceived potential for efficacy, and increase willingness to contribute by fostering social relations.[^66] The level of self-determination that people can act with increases their identification with the solution to the problem (be it contributing to an effort at a firm, or making sacrifices when one has to limit the use of a resource).

Taylor found that proposals in the US for siting “locally unwanted land uses” such as toxic waste sites, prisons, or airports, were never accepted by the residents if they lacked a platform for community engagement and deliberation, even if they offered large sums of money; whereas those that provided spaces for engagement, assurances to the community that burdens would be shared, and gave citizens a sense of a choice in the matter did find acceptance.[^67] Schlager found that in dealing with common pool resource dilemmas (such as a water shortage affecting irrigation systems or a forest shared by many different types of users) resource users can and did organize themselves to sustain the resource and outperformed central-government in their institutional arrangements, policy design for restricting use, and overall efficacy in conserving the resource. The users themselves were more in touch with the challenges facing their community, and designed more complex policies that served to monitor, manage and sustain the resource better. Homogeneity of resource users was not found to be an important factor in conservation, nor was the scale size of the resource user group, which was likely because smaller groups had less capital to draw on for constructing and implementing policy.[^68] For these reasons governmental support can take the form of actual support for local policies, rather than the imposition of policies to a problem.

All of these results provide a sketch of the conditions under which actors will be provided with good reasons for acting in accordance with the social good, and go to show that context, relations, and the identity (the ideals and norms) of the individual and the community determine levels of rational cooperative behaviour.

# 7. The Outcomes of a Reasonable Theory of Rationality

To show that rational actors value things in different ways and deliberate about actions by assessing the reasons for action in the situation, goes some way to describing how to preserve and promote the appropriate value of the goods in question and the relations between the actors. Valuing others as equals in a cooperative endeavour and endorsing a norm of fairness is potentially justifiable to everyone and can therefore be objectively endorsed. Holding one’s actions up to the standards of such an ideal can move one’s actions beyond self-interested motivations. The rational action for an actor will be addressed by determining which reasons count as good motivations for action in the context, and as such social relations which embody and express certain ways of framing the context and valuing and treating things and people are important to understanding how an individual deliberated about what to do. Titmuss said that “The ways in which society organizes and structures its social institutions can encourage or discourage the altruistic in man; such systems can foster integration or alienation”.[^69] He saw that certain relations and ideals (such as performing acts of altruism or civic duty) were not only good for efficiency and overcoming problems, but were valuable for social life and well-being in general. This is in stark contrast from Hardin’s conception of norms as guilt-inducers and in turn, pathologies.[^70] Norms and ideals are not just anxiety-inducing restrictions on our freedom, they define us and place us within our own coherent narrative of our lives and help us navigate the social contexts and problems we encounter, they present new possibilities for action, and call us to ever evaluate our action and our reasons for action as rational beings, our means, as well as our ends.

A harrowing reply to Titmuss’ results in *The Gift Relationship*, coming from Kenneth Arrow, and representing the epitome of economic thought on the matter (Sir Dennis H Robertson and Lawrence Summers have said such things), was that ethical behaviour, like all things of value to economists, needs to be economized.[^71] Not only do economists think that altruism and ethical behaviour need to be economized, they conceive of it like any other good of value, as a commodity already. Arrow avows: “I don’t want to rely too heavily on substituting ethics for self-interest… we do not wish to use up recklessly the scarce resources of altruistic motivation”.[^72] If this conception of ethical behaviour were true, it would doom us to a conception of human beings who are not capable of progression in ethical respects, who are not capable of cultivating regard for others than ourselves, or improving our virtuous action. It would advocate the extension of markets wherever possible, to save our precious ethics. It conceives of ethical behaviour as in fixed supply. But Titmuss never conceived of ethical or civic behaviour like this in his study, he saw it as something cultivated through practice, and worried that commodifying relations that were based on gift-relations would undermine such activity in other spheres of life.[^73] I am inclined to agree with Titmuss; and Aristotle’s conception of virtue as cultivated in practice; and Rousseau’s conception of civic devotion being cultivated by performing civic duty.[^74] Ethical behaviour is no commodity; it is constitutively incompatible with being bought, and in this way incommensurable with money. The things we value are not all commodities, and do not obey the laws of supply and demand or the price effect on demand. Moreover, to assume human beings are constituted in such a way to be fixed in nature with a low supply of virtuous ability, simply begs the economist’s questions about rational choice, and does an insufficient job as an explanation for much of human behaviour in the real world.

Hardin is right to say that social dilemmas have no strictly technical solutions that involve no changes in the way of human morality and values. But there are a number of solutions which do affect the supply and use of human morality and values, and change the framing, actions towards solutions, and outcomes of social problems. Of course, if one thinks that technical solutions, implementing different social relations, or commodifying a good, cannot have any effect on human “preferences” and motivating reasons for action, as Arrow and most economists do, then it is nearly impossible to grasp the way in which restricting solutions to purely market based ones will affect the nature of actors, their deliberations about their choices, and the outcomes of attempts at solutions.

**  
**

# Conclusion

None of the suggestions from empirical cases offered herein resemble Hardin’s coercion or a Hobbesian Leviathan. Although they influence actors’ reasons for action, those reasons are different in implementation, nature and effect from coercion and a loss of freedom. In fact, many of these suggestions involve an increase in self-determination and common management, rather than a decrease in freedom or a centralization of power. The impact on individuals is not one that figures in to cost-benefit analyses of Rational Choice; it impacts their framing of the situation, identification with the problem, and identity in their social relations, providing reasons for action that motivate them directly, despite potentially conflicting desires for a different action, despite the sacrifices they often have to make. Being valued in a context, being treated fairly by legitimate and effective institutions, being part of a cooperative endeavour, and identifying with the solution (e.g. contributing to a common good, or sacrificing with others) are all important to motivate individuals to act for the social good, and in effect their own well-being is increased: in the long-term the resource is larger and the payoffs are bigger, and in the short-term they are united with each other and aware of their interdependence and individual relevance.

Cooperation is an important factor explaining how human beings’ as social animals have increased their power over their circumstances. Whatever relational model is used as the basis of interaction and cooperation, be it a hierarchical (Authority Ranking) model, a Community Sharing model, an Equality Matching model or a Market model, a level of personal involvement and belief in the system must prevail for the system to be stable, compliance simply cannot be monitored and enforced everywhere without something in the way of values, norms, and ideals; and strategies (such as Tit-for-tat reciprocity) are only stable when enough actors believe in them in the first place. The norms that the relations embody and promote, and the identity of participants within their contexts, are essential to explaining and understanding behaviour. Confronting large-scale problems that have never been faced at such levels before, and with social ideals of autonomy and equality being realized to greater extents, we must interrogate the way in which social institutions are structured to ensure that they foster, rather than undermine, socially desirable behaviour. The goal is more than achieving the best payoffs for players by any means; even though more decentralized and pro-social systems are more effective than hierarchical coercion and control anyway, the types of relations in social systems are valued in themselves. Certain relations and ideals, seen as valuable to social beings’ unity, autonomy, equality, and survival, should be fostered and used wherever possible rather than breaking down social relations and reducing the need to be aware and conscientious of interdependence.

Rational actors are capable of overcoming theoretical dilemmas between their own self-interests and the collective interests. When people identify with and share reasons for action, social problems are encountered as struggles that need to be engaged with and addressed, and are seen as possibilities for collective action to overcome collective challenges. Awareness of the collective interest being in alignment with the long-term self-interest of individuals, perceived efficacy of the collective action and its dependence on individuals, and looking beyond self-interest to the framing and general importance of the problem itself, are extremely important factors to address in confronting any social problem with the theoretical form of a social dilemma. Social problems are more than the absence of markets, and are not outcomes of a supposed innate self-interest in human nature that motivates all action, they are structural problems and as such they require changes to the structural relations contributing to those problems. This involves addressing the relations of social institutions that contribute to self-interested behaviour and crowd out moral and intrinsic values as reasons for action, and addressing a lack of awareness of one’s effects on the problem, the interdependence of the collective, and possibilities for tackling problems collectively. Once we take a purely market based relational model for granted to explain human behaviour, describe failures in the market, and guide our solutions, it is no wonder that the assumptions come to life and are confirmed when those market solutions and norms are imposed everywhere. We cannot overlook the effects of the structural relation itself on norms that influence individual behaviour, and the contribution of structural relations to the problem in the first place. The Rational Choice model is radically incomplete in its description of rational individuals’ behaviour, individuals who value many things in different ways which aren’t commensurable with money, and who deliberate about courses of action which often have nothing to do with analyses of personal costs and benefits, but are rather based on consideration of reasons for action. The theorems for General Equilibrium are radically wrong in supposing that we should commodify and privatize everything of value to human beings to address the incompleteness and inefficiency of markets, and thereby solve all social problems, let alone in supposing that it is even possible to do such a thing!

# Bibliography 

Anderson, E., *Value in Ethics and Economics*, Cambridge MA: Harvard University Press, 1993

Aristotle, *Nichomachean Ethics*, trans. David Ross, New York: Oxford University Press, 1925, Book II, Ch 1, (1103a-1103b)

Arrow, K.J., “Contingent Valuation of Nonuse Values: Observations and Questions,” Chap XIV in Jerry A Hausman, ed., *Contingent Valuation: A Critical Assessment* , Amsterdam: North-Holland, 1993

Arrow, K., “Gifts and Exchanges” in *Philosophy and Public Affairs*, 1972, vol. 1, no. 4

Axelrod, R. *The Evolution of Co-operation.* New York: Penguin, 1990.

Bewley, T.,*Why Wages Don’t Fall During a Recession,* Cambridge, MA: Harvard University Press, 1999

Cialdini, R.B., Reno, R.R. & Kallgren, C.A., “A focus theory of normative conduct: Recycling the concept of norms to reduce littering in public places,” in *Journal of Personality and Social Psychology*, 58 (1990), pp. 1015–1026

Cropanzo, R. & Byrne, Z.S., “Workplace Justice and the Dilemma of Organizational Citizenship”Ch 8 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000, 142-161

Dancy, J., *Practical Reality*, Oxford: Oxford University Press, 2000

Elffers, H., “But Taxpayers Do Cooperate!”Ch 10 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000, 184-194

Eiser, J.R. & Bhavnani, K.K., “The Effect of Situational Meaning on the Behaviour of Subjects in the Prisoner's Dilemma Game” in *European Journal of Social Psychology,* 4 (1), (1974) 93-97

Ellingsen, T., Johannesson, M., Mollerstrom, J., Munkhammar, S. “Social framing effects: Preferences or beliefs?” In *Games and Economic Behavior* 76 (1), (2012)

Elster, J., “The Market and the Forum: Three Varieties of Political Activity” in Jon Elster and Aanund Hylland eds., *Foundations of Social Choice Theory*, Cambridge: Cambridge University Press, 1986

Fiske, A., "The four elementary forms of sociality: framework for a unified theory of social relations." In *Psychological review* 99, no. 4 (1992) 689

Frey, B.S., & Oberholzer-Gee, F., “The Cost of Price Incentives: An Empirical Analysis of Motivation Crowding-Out”, in *American Economic Review* 87, no. 4 (September 1997): 753

Gneezy, U., and Rusticini, A., “A Fine is a Price”, in *Journal of Legal Studies* 29, no. 1 (January 2000) 1-17

Gneezy, U., and Rusticini, A., “Pay Enough or Don’t Pay at All”, in *Quarterly Journal of Economics* (August 2000): 798-99

Hardin, G., “The Tragedy of the Commons”, Published in *Science*, 142 (1968) December 13

Hardin, G., “The Tragedy of the Unmanaged Commons” Chap 7 in Dustin J. Pen, Iver Mysterud eds., *Evolutionary Perspectives of Environmental Problems*, London: Transaction Publishers, 2007

Hatcher, A., Thebaud, O. & Jaffry, S., “An Economic Analysis of Compliance with Fishery Regulations” Ch 5 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000, 83-101

Houtven, G., Mansfield, C. & Huber, J., “Compensating for Public Harms: Why Public Goods are Preferred to Money,” in *Land Economics* 78, no. 3 (August 2002): 368-89

Hristova, E., Grinberg, M., Georgieva, I., Borisova, M., “Cooperation in Prisoner’s Dilemma Game: Influence of Players’ Social Roles*”* in *Proceedings of Cognitive Science* (2012)

Hume, D., 1739, *A Treatise of Human Nature*, New York: Oxford University Press, 2000

Klandermans, B., “Identity and Protest: how group identification helps to overcome collective action dilemmas” Ch 9 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000, 162-83

Kreps, D.M., *A Course in Microeconomic Theory*, New Jersey: Princeton University Press, 1990

Peters, T.J., and Waterman, R.H., *In Search of Excellence: Lessons from America’s Best Run Companies*, New York: Harper and Row, 1982

Raz, J. *Practical Reason and Norms,* London: Hutchinson, 1975

Rousseau, J.J., *The Social Contract*, trans. GDH Cole, rev. ed., New York: Knopf, 1993, Book III, Ch 15, 239-40

Sally, D., “On Sympathy and Games”, in *Journal of Economic Behavior & Organization*, 44, (2000) 22-30

Sandel, M.,*What Money Can’t Buy: The Moral Limits of Markets*, Parktown North: Penguin, 2012

Satz, D.,*Why Some Things Should Not Be For Sale: The Moral Limits of Markets*, Oxford: Oxford University Press, 2010

Scheuler, G.F., *Desire: Its Role in Practical Reason and the Explanation of Action,* Cambridge, MA: MIT Press, 1995

Schlager, E., “Collective Cooperation in Common Pool Resources” Ch 6 in Mark Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000, 102-122

Snyder, M., & Omoto, A.M., “Doing Good for Self and Society: volunteerism and the psychology of citizen participation” Ch 7 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000

Taylor, M., *Rationality and the Ideology of Disconnection*, New York: Cambridge University Press, 2006

Tenbrunsel, A.E., & Messick, D.M., “Sanctioning Systems, Decision Frames, and Cooperation,” in *Administrative Science Quarterly,* 44 no. 4 (December 1999) 698

Titmuss, R., *The Gift Relationship: From Human Blood to Social Policy*, New York: Pantheon, 1971

Tyler, T.R., “Why Do People Cooperate in Groups? Support for structural solutions to social dilemma problems”Ch 4 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000, 64-82

Van Lange, P., Van Vugt, M., & de Cremer, D., “Choosing Between personal Comfort and the Environment” Ch 3 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000

Van Vugt, M., Snyder, M., Tyler, T.R., Biel, A., “Perspectives on Cooperation in Modern Society: helping the self, the community, and society” Ch 1 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, London: Routledge, 2000

Varian, H.R., *Intermediate Micro Economics*, seventh ed., New York: W.W Norton, 2006

Walton, R.E., “From Control to Commitment in the Workplace,” in *Harvard Business Review*, 63 (1985) 77-84

Whyte, W.F., *Money and Motivation: An Analysis of Incentives in Industry*, New York, Harper and Row: 1955

Wiggins, D. *Needs, Values, Truth*, Third ed., New York: Oxford University Press, 1998

# Plagiarism Declaration

DECLARATION:

1.  I know that plagiarism is wrong. Plagiarism is to use another’s work and to pretend that it is one’s own.

2.  I have used the footnote convention for citation and referencing. Each contribution to, and quotation in, this dissertation from the work(s) of other people has been attributed, and has been cited and referenced.

3.  This dissertation is my own work.

4.  I have not allowed, and will not allow, anyone to copy my work with the intention of passing it off as his or her own work.

5.  I acknowledge that copying someone else’s assignment or essay, or part of it, is wrong, and declare that this is my own work.

Signature: ………………………………….. Date: …………………………………

Word count: ………..

[^1]: Garret Hardin, “The Tragedy of the Commons”, Published in *Science*, 142 (1968) December 13. 1243

[^2]: Hal. R Varian, *Intermediate Micro Economics*, seventh ed. (New York: W.W Norton, 2006) 34

[^3]: Kenneth J. Arrow. “Contingent Valuation of Nonuse Values: Observations and Questions,” Chap XIV in Jerry A Hausman, ed., *Contingent Valuation: A Critical Assessment* (Amsterdam: North-Holland, 1993)

[^4]: Varian, op.cit. 35

[^5]: David Wiggins, *Needs, Values, Truth*, Third ed. (New York: Oxford University Press, 1998) 375

[^6]: Hardin, “The Tragedy of the Commons”, 1245

[^7]: Ibid.

[^8]: Garret Hardin, “The Tragedy of the Unmanaged Commons” Chap 7 in Dustin J. Pen, Iver Mysterud eds., *Evolutionary Perspectives of Environmental Problems*, (London: Transaction Publishers, 2007)

[^9]: Robert Axelrod, *The Evolution of Co-operation,* (New York: Penguin, 1990) 217-219

[^10]: Hardin, “The Tragedy of the Commons”, 1243

[^11]: Ibid. 1247

[^12]: Hardin, “The Tragedy of the Commons”, 1246

[^13]: Michael Sandel, *What Money Can’t Buy: The Moral Limits of Markets*, (Parktown North: Penguin, 2012) 87

[^14]: Debra Satz, *Why Some Things Should Not Be For Sale: The Moral Limits of Markets*, (Oxford: Oxford University Press, 2010) 18

[^15]: David M. Kreps, *A Course in Microeconomic Theory* (New Jersey: Princeton University Press, 1990)

[^16]: Satz, op.cit. 33

[^17]: Ibid. 112

[^18]: Michael Taylor, *Rationality and the Ideology of Disconnection*, (New York: Cambridge University Press, 2006) 64

[^19]: Sandel, op.cit. 115

[^20]: Ibid. 116

[^21]: Bruno S. Frey & Felix Oberholzer-Gee, “The Cost of Price Incentives: An Empirical Analysis of Motivation Crowding-Out”, in *American Economic Review* 87, no. 4 (September 1997): 753

[^22]: Carol Mansfield, George Houtven & Joel Huber, “Compensating for Public Harms: Why Public Goods are Preferred to Money,” in *Land Economics* 78, no. 3 (August 2002): 368-89

[^23]: Sandel op.cit. 119; Taylor op.cit 160; Uri Gneezy & Aldo Rusticini, “A Fine is a Price”, in *Journal of Legal Studies* 29, no. 1 (January 2000) 1-17

[^24]: Sandel op. cit. 118; Uri Gneezy & Aldo Rusticini, “Pay Enough or Don’t Pay at All”, in *Quarterly Journal of Economics* (August 2000) 798-99

[^25]: Gneezy & Rusticini, loc.cit. 799-803

[^26]: Richard Titmuss, *The Gift Relationship: From Human Blood to Social Policy,* (New York: Pantheon, 1971) 277

[^27]: Ibid. 224

[^28]: Joseph Raz, *Practical Reason and Norms,* (London: Hutchinson, 1975) sec. 1.2

[^29]: Kenneth Arrow, “Gifts and Exchanges” in *Philosophy and Public Affairs*, 1972, vol. 1, no. 4

[^30]: Jon Elster, “The Market and the Forum: Three Varieties of Political Activity” in Jon Elster and Aanund Hylland eds., *Foundations of Social Choice Theory*, (Cambridge: Cambridge University Press, 1986) 115

[^31]: Taylor op.cit., 45

[^32]: David Hume,1739, *A Treatise of Human Nature*, (New York: Oxford University Press, 2000) 266

[^33]: Taylor op.cit., 41

[^34]: Ibid., 50

[^35]: George F. Scheuler, *Desire: Its Role in Practical Reason and the Explanation of Action,* (Cambridge, MA: MIT Press, 1995) 20-2; Jonathan Dancy, *Practical Reality* (Oxford: Oxford University Press, 2000) 80

[^36]: Arrow, “Gifts and Exchanges,” op.cit., 349-51

[^37]: Ibid.

[^38]: Wiggins, op.cit. 371

[^39]: Wiggins, op.cit., 371

[^40]: Ibid., 373

[^41]: Satz, op.cit. 49

[^42]: Wiggins, op.cit., 378 & 385

[^43]: Elizabeth Anderson, *Value in Ethics and Economics*, (Cambridge MA: Harvard University Press, 1993) 106-107

[^44]: Ibid., 107-108

[^45]: Ibid. 108-109

[^46]: Taylor, op.cit. 34-37

[^47]: Mark Van Vugt et al., “Perspectives on Cooperation in Modern Society: helping the self, the community, and society” in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 5

[^48]: Mark Snyder & Allen M. Omoto, “Doing Good for Self and Society: volunteerism and the psychology of citizen participation” Ch 7 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 130-40

[^49]: Van Lange et al., “Choosing Between personal Comfort and the Environment” Ch 3 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 51

[^50]: David Sally, “On Sympathy and Games”, in *Journal of Economic Behavior & Organization*, 44, (2000) 22-30

[^51]: Robert B. Cialdini, Raymond R. Reno, Carl A. Kallgren, “A focus theory of normative conduct: Recycling the concept of norms to reduce littering in public places,” in *Journal of Personality and Social Psychology*, 58 (1990) 1015–1026

[^52]: Axelrod, op.cit., 33-36

[^53]: Johanna Mollerstrom et al., “Social framing effects: Preferences or beliefs?” in *Games and Economic Behavior*, 76 (1), 117–130; as well as in: J. Richard Eiser & Kum-Kum Bhavnani, “The effect of situational meaning on the behaviour of subjects in the prisoner's dilemma game” in *European Journal of Social Psychology*, 4 (1), (1974) 93-97.

[^54]: Evgenia Hristova et al., “Cooperation in Prisoner’s Dilemma Game: Influence of Players’ Social Roles*”* in *Proceedings of Cognitive Science* (2012) 2583

[^55]: Ann E. Tenbrunsel and David M. Messick “Sanctioning systems, Decision Frames, and Cooperation,” in *Administrative Science Quarterly,* 44 no. 4 (December 1999) 698

[^56]: Alan Fiske, "The four elementary forms of sociality: framework for a unified theory of social relations." In *Psychological review* 99, no. 4 (1992) 689

[^57]: Bert Klandermans, “Identity and Protest: how group identification helps to overcome collective action dilemmas” Ch 9 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 170-83

[^58]: Aaron Hatcher et al., “An Economic Analysis of Compliance with Fishery Regulations” Ch 5 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 95

[^59]: Ibid., 98

[^60]: Henk Elffers, “But Taxpayers Do Cooperate!”Ch 10 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 186

[^61]: Tom R. Tyler, “Why Do People Cooperate in Groups? Support for structural solutions to social dilemma problems” Ch 4 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 67 & 77

[^62]: Russell Cropanzo & Zinta S. Byrne, “Workplace Justice and the Dilemma of Organizational Citizenship” Ch 8 in Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 144-156

[^63]: Thomas J. Peters and Robert H. Waterman, *In Search of Excellence: Lessons from America’s Best Run Companies* (New York: Harper and Row, 1982); Truman Bewley, *Why Wages Don’t Fall During a Recession* (Cambridge, MA: Harvard University Press, 1999); Richard E. Walton, “From Control to Commitment in the Workplace,” in *Harvard Business Review*, 63 (1985) 77-84; William F. Whyte, *Money and Motivation: An Analysis of Incentives in Industry* (New York, Harper and Row: 1955).

[^64]: Taylor, op.cit., 189-207

[^65]: Ibid.; see also: Edella Schlager cited in footnote 66

[^66]: Van Vugt et al., op.cit., 58-9

[^67]: Taylor, op.cit., 176-178

[^68]: Edella Schlager, “Collective Cooperation in Common Pool Resources” Ch 6 in Mark Van Vugt et al. eds., *Cooperation in Modern Society: Promoting the Welfare of Communities, States and Organizations*, (London: Routledge, 2000) 107-113

[^69]: Titmuss loc.cit, 270-274

[^70]: Hardin, “The Tragedy of the Commons”, 1245

[^71]: Sandel, loc.cit., 127

[^72]: Arrow, loc.cit, 354-55

[^73]: Titmuss loc.cit., 244

[^74]: Aristotle, *Nichomachean Ethics*, trans. David Ross (New York: Oxford University Press, 1925), Book II, Ch 1, (1103a-1103b); Jean-Jacques Rousseau, The Social Contract, trans. G.D.H Cole, rev. ed. (New York: Knopf, 1993), Book III, Ch 15, 239-40

